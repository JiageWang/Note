# 机器学习之评估方法与性能度量机器python实现
## 一、评估方法
---
### 1. 留出法(hold-out)
**方法概述**：直接将数据集$D$划分成训练集$S$与测试集$T$,需保留数据分布的一直性，常采用“分层采样”。一般采用若干次随机划分重复实验评估后取平均值。  

**特点**: 若$S$增大，训练出的模型更接近用$D$训练的模型，但评估结果不够稳定准确，存在估计偏差；若$T$增大，训练出的模型与用D训练的模型可能有较大差别，失去保真。

**python实现**：
```python
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.4) #普通采样
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.4, stratify=y) #分层采样
```

### 2. k折交叉验证法(k-fold cross validation)
**方法概述**：将数据集$D$通过分层采样划分成k份互斥子集$D_1,D_2,...,D_k$，每次取其中一份作为测试集，其余作为训练集。重复训练测试k次取均值。一般采用不同的划分方法进行p次实验，即p次k折交叉验证，共进行p*k次训练与测试。特别的，当测试集样本数为1时，称为 *留一法*(leave-one-out)，由于训练集更接近$D$，评估结果往往更准确。  
![PzOOAI.png](https://s1.ax1x.com/2018/09/03/PzOOAI.png)

**特点**：当数据集比较大时，训练模型开销大。估计偏差小

**python实现**：
```python
from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score, LeaveOneOut

# 10折交叉验证普通采样
kf=KFold(n_splits=10) 
for train_index,test_index in kf.split(X):
    X_train, X_test=X[train_index], X[test_index]
    y_train, y_test=y[train_index], y[test_index]

# 10折交叉验证分层采样版
stfkf=StratifiedKFold(n_splits=10) 
for train_index,test_index in stfkf.split(X,y):
    X_train, X_test=X[train_index], X[test_index]
    y_train, y_test=y[train_index], y[test_index]

# 直接获取该学习器在k折交叉获取的最佳性能
result = cross_val_score(clf, X, y, cv=10) # 返回长度为10的得分列表，常取均值作为最终得分

# 留一法
loo = LeaveOneOut()
for train_index,test_index in loo.split(X,y):
    X_train, X_test=X[train_index], X[test_index]
    y_train, y_test=y[train_index], y[test_index]
```
### 3. 自助法(bootstrapping)
**方法概述**：对数据集$D$进行多次自助采样(可重复采样)产生具有相同样本数量的数据集$D'$，使用$D'$作为训练集，$D/D'$做测试集，这样使实际评估模型与期望评估模型使用了相同的样本数。由
$$ \lim_{m\to \infty}(1-\frac{x}{y})^m→\frac{1}{e}\approx0.368 $$
可得，任有约占1/3没在训练集中出现的样本用于测试。  

**特点**：改变了初始数据集的分布，会引入估计偏差。适用于数据集小，训练测试集不易划分的情况。适用于集成学习。 

**python实现**：
```python
import pandas as pd
import numpy as np
data = np.hstack((X,y))
data = pd.DataFrame(data)
train = data.sample(frac=1.0,replace=True) #自助抽样，frac为1代表抽样个数与样本个数相等
test = data.loc[data.index.difference(train.index)].copy()
```

### 4 调参与最终模型
一般将数据集划分成训练集，测试集，使用训练集来评估模型泛化性能，将训练集另外划分成训练集与验证集，使用验证集来进行模型选择与调参。由于训练评估过程总是预留部分数据作为评估测试，实际上只使用了部分数据训练模型。最终模型需要用整个数据集D重新训练。

## 二、性能度量  
---
回归任务常使用均方误差作为性能度量，本小节主要介绍分类任务中的性能度量  

### 1. 错误率与精度
**精度**：分类正确的样本占总样本的比例。
**错误率**：分类错误的样本占总样本的比例
**python实现**：
```python
from sklearn.metrics import accuracy_score
acc = accuracy_score(y_true, y_pred) # 准确率
```

### 2. 混淆矩阵(confusion matrix)
**混淆矩阵**：刻画一个分类器对每一个类别的分类准确程度，对于二元分类，其混淆矩阵如下图所示
![iSNub6.png](https://s1.ax1x.com/2018/09/04/iSNub6.png)

**python实现**：
```python
from sklearn.metrics import confusion_matrix
confusion_matrix(y_true,y_predict)
```
**真正例(TP)**：真实为正例，预测也为正例。
**假正例(FP)**：真实为反例，预测为正例
**真反例(TN)**：真实为反例，预测也为反例
**假反例(FN)**：真实为正例，预测为反例  

**真正率(TPR)**：正样本预测结果数 / 正样本实际数
$$TPR=\frac{TP}{TP+FN}$$
**真负率(TNR)**：负样本预测结果数 / 负样本实际数
$$TNR=\frac{TN}{TN+FP}$$
**假正率(FPR)**：被预测为正的负样本结果数 /负样本实际数
$$FPR=\frac{FP}{TN+FP}$$
**假负率(FNR)**：被预测为负的正样本结果数 / 正样本实际数
$$FNR=\frac{FN}{TP+FN}$$

### 3. 查全率(recall)、查准率(precision)与$F_1$、$F_\beta$
**查全率**：也叫召回率，从想要检索的信息中被检索出来的比例。
$$P=\frac{TP}{TP+FP}$$
**查准率**：也叫准确率，检索出来的信息中想要检索的信息占比。
$$R=\frac{TP}{TP+FN}$$
一般来说，查准率与查全率互相矛盾，查准率高时查全率一般偏低，查全率高时查准率偏低。
**$F_1$**：基于查全率与查准率的调和平均。
$$\frac{1}{F_1}=\frac{1}{2}\cdot(\frac{1}{P}+\frac{1}{R})$$
**$F_\beta$**：基于查全率与查准率的加权调和平均。当$\beta>1$,查全率有更大影响，$\beta<1$,查准率有更大影响，
$$\frac{1}{F_\beta}=\frac{1}{1+\beta}\cdot(\frac{1}{P}+\frac{\beta^2}{R})$$
**python实现**：
```python
from sklearn.metrics import precision_score, recall_score, f1_score
P = precision_score(y_true,y_predict) # 查准率
R = recall_score(y_true,y_predict) # 查全率
F1 = f1_score(y_true,y_predict) # F1
```

### 4. PR图
![iSaa4S.png](https://s1.ax1x.com/2018/09/04/iSaa4S.png)
**画法**：将分类器的预测结果进行排序，按此顺序逐个把样本作为正例进行预测，计算每次预测结果的查全率与查准率，以查准率为纵轴，查全率为横轴作图。
**特点**：直观显示学习器在样本总体上的查全率与查准率。当学习器A的PR曲线完全被学习器B的PR曲线包住，则B的分类性能由于A。
**平衡点**(Break-Even Point，简称BEP):查准率与查全率相等时的取值。
**python实现**：
```python
from sklearn.metrics import precision_recall_curve
import matplotlib.pyplot as plt
precisions,recalls,thresholds = precision_recall_curve(y_test,decsion_scores) #获得P，R值
plt.plot(recalls, precisions)
plt.show()
```

### 5. ROC与AUC
**ROC**：全称为“受试者工作特征”(Receiver Operation Characteristic)
**画法**：与PR图类似，将分类器的预测结果进行排序，按此顺序逐个把样本作为正例进行预测，计算每次预测结果的真正率与假正率，以真正率为纵轴，假正率为横轴作图
**AUC**：ROC曲线下的面积(Area Under ROC Curve)
**python实现**
```python
fpr, tpr, thresholds = roc_curve(y_test, decsion_scores) # 获得真正率与假正率
roc_auc = auc(fpr, tpr) # 获得AUC值
plt.plot(fpr, tpr)
plt.show()
print("auc=",roc_auc)
```